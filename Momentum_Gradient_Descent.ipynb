{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxYPIGo9CtIJe4EZwfZ22U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ak08032000/Gradient-Descent/blob/master/Momentum_Gradient_Descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is Momentum based Gradient Descent?\n",
        "Momentum gradient descent is a variant of the standard gradient descent optimization algorithm used in machine learning. In momentum gradient descent, a \"momentum\" term is added to the weight updates, which helps to speed up convergence and reduce oscillations. The momentum term is a moving average of the past gradients, and its effect is to dampen the oscillations in the gradient descent updates and smooth out the weight updates over time. Specifically, the momentum term accelerates the gradient descent algorithm in the relevant direction and decelerates it in irrelevant directions. The update rule for the weights using momentum gradient descent includes the current gradient and a fraction of the previous velocity, and it can be mathematically expressed as:\n",
        "\n",
        "v(t) = beta * v(t-1) + (1-beta) * gradient\n",
        "weight(t) = weight(t-1) - learning_rate * v(t)\n",
        "\n",
        "where v(t) is the velocity vector at time t, beta is a hyperparameter that controls the momentum effect, and learning_rate is the step size parameter."
      ],
      "metadata": {
        "id": "JPG5Yr5vbaQ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skizXOHARb46"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = [0.5, 2.5]\n",
        "Y = [0.2, 0.9]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(w,x,b):\n",
        "  return 1.0 / 1.0 + np.exp(-(w*x + b))"
      ],
      "metadata": {
        "id": "OKHcJnjPRxyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def error(w,b):\n",
        "  err = 0.0\n",
        "  for x,y in zip(X,Y):\n",
        "    fx = f(w,x,b)\n",
        "    err += 0.5 * (fx - y)**2\n",
        "  return err"
      ],
      "metadata": {
        "id": "QOQ8m85TSTtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_w(w, b, x, y):\n",
        "  fx = f(w, x, b)\n",
        "  return (fx - y) * fx * (1 - fx) * x\n",
        "\n",
        "def grad_b(w, b, x, y):\n",
        "  fx = f(w, x,b)\n",
        "  return (fx - y) * fx * (1 - fx)\n",
        "  "
      ],
      "metadata": {
        "id": "HSONZU3XTOXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_momentum_gradient_descent():\n",
        "  w, b, eta, max_epochs = 0, 0, 1.0, 100\n",
        "  prev_v_w, prev_v_b, gamma = 0, 0, 0.9\n",
        "  for i in range(max_epochs):\n",
        "    dw, db = 0, 0\n",
        "    for x,y in zip(X,Y):\n",
        "      dw += grad_w(w, b, x, y)\n",
        "      db += grad_b(w, b, x, y)\n",
        "\n",
        "    v_w = gamma * prev_v_w + eta* dw\n",
        "    v_b = gamma * prev_v_b + eta* db\n",
        "    w = w - v_w\n",
        "    b = b - v_b\n",
        "    prev_v_w = v_w\n",
        "    prev_v_b = v_b\n",
        "    print(w,b)"
      ],
      "metadata": {
        "id": "jNlZkqYQUett"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "do_momentum_gradient_descent()"
      ],
      "metadata": {
        "id": "h_IU6FB_WcF9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e52302f-2caa-4b69-c3f3-4faa93ac449b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.3 5.800000000000001\n",
            "13.870031481408173 11.020062962801983\n",
            "19.78305982104742 15.718119642067553\n",
            "25.104785326725764 19.946370653412604\n",
            "29.894338281836276 23.751796563623156\n",
            "34.204935941435735 27.176679882812653\n",
            "38.08447383507525 30.2590748700832\n",
            "41.57605793935082 33.033230358626696\n",
            "44.71848363319883 35.52997029831584\n",
            "47.54666675766204 37.77703624403607\n",
            "50.09203156967892 39.79939559518427\n",
            "52.38285990049412 41.619519011217655\n",
            "54.44460539822779 43.257630085647705\n",
            "56.3001763461881 44.731930052634745\n",
            "57.97019019935238 46.05880002292308\n",
            "59.47320266720023 47.25298299618258\n",
            "60.8259138882633 48.32774767211613\n",
            "62.04335398722006 49.29503588045633\n",
            "63.139050076281144 50.16559526796251\n",
            "64.12517655643612 50.94909871671807\n",
            "65.01269038857559 51.65425182059808\n",
            "65.81145283750112 52.28888961409008\n",
            "66.5303390415341 52.860063628232886\n",
            "67.17733662516379 53.37412024096141\n",
            "67.7596344504305 53.83677119241708\n",
            "68.28370249317054 54.25315704872719\n",
            "68.75536373163658 54.627904319406284\n",
            "69.17985884625601 54.96517686301747\n",
            "69.5619044494135 55.268722152267536\n",
            "69.90574549225525 55.54191291259259\n",
            "70.21520243081281 55.787784596885146\n",
            "70.49371367551461 56.00906911274844\n",
            "70.74437379574624 56.20822517702541\n",
            "70.96996790395471 56.38746563487468\n",
            "71.17300260134233 56.548782046939024\n",
            "71.35573382899119 56.693966817796934\n",
            "71.52019193387517 56.82463311156905\n",
            "71.66820422827074 56.94223277596396\n",
            "71.80141529322675 57.048072473919376\n",
            "71.92130525168717 57.14332820207925\n",
            "72.02920621430155 57.22905835742314\n",
            "72.12631708065449 57.30621549723264\n",
            "72.21371686037213 57.37565692306119\n",
            "72.292376662118 57.43815420630688\n",
            "72.36317048368929 57.494401761228005\n",
            "72.42688492310344 57.54502456065702\n",
            "72.4842279185762 57.59058508014313\n",
            "72.53583661450166 57.631589547680626\n",
            "72.58228444083458 57.66849356846438\n",
            "72.62408748453421 57.70170718716975\n",
            "72.66171022386388 57.73159944400459\n",
            "72.69557068926058 57.75850247515594\n",
            "72.7260451081176 57.78271520319216\n",
            "72.75347208508893 57.804506658424756\n",
            "72.77815636436313 57.824118968134094\n",
            "72.8003722157099 57.8417700468725\n",
            "72.820366481922 57.85765601773706\n",
            "72.83836132151288 57.87195339151516\n",
            "72.85455667714467 57.88482102791546\n",
            "72.86913249721329 57.89640190067573\n",
            "72.88225073527505 57.906824686159965\n",
            "72.89405714953064 57.91620519309578\n",
            "72.90468292236066 57.92464764933801\n",
            "72.91424611790768 57.932245859956026\n",
            "72.9228529939 57.939084249512234\n",
            "72.93059918229308 57.945238800112826\n",
            "72.93757075184686 57.95077789565335\n",
            "72.94384516444526 57.95576308163983\n",
            "72.94949213578383 57.96024974902766\n",
            "72.95457440998854 57.96428774967671\n",
            "72.95914845677277 57.96792195026085\n",
            "72.96326509887858 57.971192730786576\n",
            "72.9669700767738 57.97413643325973\n",
            "72.97030455687951 57.976785765485566\n",
            "72.97330558897465 57.97917016448882\n",
            "72.97600651786027 57.98131612359175\n",
            "72.97843735385733 57.98324748678439\n",
            "72.98062510625468 57.984985713657764\n",
            "72.9825940834123 57.9865501178438\n",
            "72.98436616285416 57.98795808161123\n",
            "72.98596103435183 57.98922524900192\n",
            "72.98739641869973 57.99036569965354\n",
            "72.98868826461285 57.991392105239996\n",
            "72.98985092593465 57.99231587026781\n",
            "72.99089732112427 57.99314725879284\n",
            "72.99183907679493 57.993895508465364\n",
            "72.99268665689853 57.99456893317064\n",
            "72.99344947899176 57.99517501540539\n",
            "72.99413601887568 57.99572048941666\n",
            "72.9947539047712 57.99621141602681\n",
            "72.99531000207718 57.99665324997594\n",
            "72.99581048965254 57.99705090053016\n",
            "72.99626092847038 57.997408786028956\n",
            "72.99666632340643 57.99773088297787\n",
            "72.99703117884887 57.998020770231896\n",
            "72.99735954874707 57.99828166876052\n",
            "72.99765508165545 57.99851647743628\n",
            "72.99792106127299 57.998727805244464\n",
            "72.99816044292878 57.99891800027183\n",
            "72.99837588641898 57.999089175796456\n"
          ]
        }
      ]
    }
  ]
}